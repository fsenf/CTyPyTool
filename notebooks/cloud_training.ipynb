{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "controlled-aruba",
   "metadata": {},
   "source": [
    "### Import Libraries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 142,
   "id": "living-exchange",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import xarray as xr\n",
    "import h5py \n",
    "import random\n",
    "\n",
    "from sklearn import tree\n",
    "import graphviz\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "import cartopy.crs as ccrs\n",
    "import cartopy\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "caroline-might",
   "metadata": {},
   "source": [
    "### Define Plotting Methods"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "linear-value",
   "metadata": {},
   "outputs": [],
   "source": [
    "def addSubplot(data, variable = None, lons = None, lats = None, time = 0, index = 0, size_x = 1, size_y = 1):\n",
    "\tif lons is None or lats is None:\n",
    "\t\ttry:\n",
    "\t\t\tlons = data.variables['lon']\n",
    "\t\t\tlats = data.variables['lat']\n",
    "\t\texcept Exception:\n",
    "\t\t\tprint(\"Longitude/Lattide variables not found!\")\n",
    "\t\t\treturn\n",
    "\textent = [lons.min(), lons.max(), lats.min(), lats.max()]\n",
    "\tax = plt.subplot(size_x,size_y,index, projection=ccrs.PlateCarree())\n",
    "\tax.set_extent(extent, crs=ccrs.PlateCarree())\n",
    "\tax.coastlines(resolution='50m')\n",
    "\tax.add_feature(cartopy.feature.LAKES, edgecolor='black')\n",
    "\tax.add_feature(cartopy.feature.RIVERS)\t\n",
    "\tif variable == None:\n",
    "\t\tax.contourf(lons, lats, data ,cmap = \"jet\")\n",
    "\telse:\n",
    "\t\tax.contourf(lons, lats, data[variable][time],cmap = \"jet\")\n",
    "\n",
    "        \n",
    "        \n",
    "def plotData(data, lons, lats):\n",
    "\tplt.figure(figsize=(12, 4))\n",
    "\textent = [lons.min(), lons.max(), lats.min(), lats.max()]\n",
    "\tax = plt.axes(projection=ccrs.PlateCarree())\n",
    "\tax.set_extent(extent)\n",
    "\tax.gridlines()\n",
    "\tax.coastlines(resolution='50m')\n",
    "\tax.add_feature(cartopy.feature.OCEAN)\n",
    "\tax.add_feature(cartopy.feature.LAND, edgecolor='black')\n",
    "\tax.add_feature(cartopy.feature.LAKES, edgecolor='black')\n",
    "\tax.add_feature(cartopy.feature.RIVERS)\t\n",
    "\tax.contourf(lons, lats, data, cmap = \"jet\")\n",
    "\tplt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "dress-monte",
   "metadata": {},
   "source": [
    "##### Read trainig-data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "specified-spider",
   "metadata": {},
   "outputs": [],
   "source": [
    "data_directory = \"../data/\"\n",
    "filename_labels = \"nwcsaf_msevi-nawdex-20160925.nc\"\n",
    "filename_data = \"msevi-nawdex-20160925.nc\"\n",
    "filename_mask = \"region_masks_for_msevi_nawdex.h5\"\n",
    "\n",
    "sat_data = xr.open_dataset(data_directory+filename_data)\n",
    "label_data = xr.open_dataset(data_directory+filename_labels)\n",
    "mask_data = h5py.File(data_directory+filename_mask, 'r')\n",
    "\n",
    "lons = sat_data['lon']\n",
    "lats = sat_data['lat']\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "female-utilization",
   "metadata": {},
   "source": [
    "##### Convert mask to xr-Dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "raised-armor",
   "metadata": {},
   "outputs": [],
   "source": [
    "dims = ['rows', 'cols']\n",
    "coords = {'lat': sat_data.coords['lat'], 'lon':sat_data.coords['lon']}\n",
    "\n",
    "mask_ds = xr.Dataset()\n",
    "for key in mask_data.keys():\n",
    "\tif key == \"_source\":\n",
    "\t\tcontinue\n",
    "\tm = xr.DataArray([row for row in mask_data[key]], dims = dims, coords = coords, name = key + \"_mask\")\n",
    "\tmask_ds[key + \"_mask\"] = m\n",
    "\n",
    "    "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "likely-capability",
   "metadata": {},
   "source": [
    "##### Select Data Points for learning"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 163,
   "id": "surprising-marble",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(array([316, 316, 316, ..., 714, 714, 714]), array([1904, 1905, 1906, ..., 2169, 2170, 2171]))\n"
     ]
    }
   ],
   "source": [
    "n = 100 \n",
    "# number of points from the mapped dataset choose for learning \n",
    "#(each point is sampled 24x, once for every timeframe)\n",
    "\n",
    "# extract all indices that lie inside mapped area\n",
    "mapped_indeces = np.where(mask_ds[\"mediterranean_mask\"])\n",
    "# create a selection of 'n' index-pairs\n",
    "selection = random.sample(list(zip(mapped_indeces[0],mapped_indeces[1])),n)\n",
    "ind_x, ind_y = zip(*selection)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "collect-suspect",
   "metadata": {},
   "source": [
    "##### Extract trainig samples and corresponding labels"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 144,
   "id": "catholic-commons",
   "metadata": {},
   "outputs": [],
   "source": [
    "training_data = []\n",
    "for variable in sat_data.variables:\n",
    "     # only use relevant channels\n",
    "     if \"bt\" in variable:\n",
    "        # single channel, 24*n values\n",
    "        entry = np.array(sat_data[variable])[:,ind_x,ind_y].flatten() \n",
    "        training_data.append(entry)\n",
    "        \n",
    "# reshape from (variables, samples) --> (samples, variables) \n",
    "training_data = np.array(training_data)        \n",
    "sp = training_data.shape\n",
    "training_data = training_data.flatten().reshape(sp[1],sp[0], order='F')\n",
    "\n",
    "\n",
    "labels = np.array(label_data[\"CT\"])[:,ind_x,ind_y].flatten()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "informed-macintosh",
   "metadata": {},
   "source": [
    "##### Train classifier with selected data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 145,
   "id": "balanced-quest",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "DecisionTreeClassifier()"
      ]
     },
     "execution_count": 145,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "cl = tree.DecisionTreeClassifier()\n",
    "cl.fit(training_data, labels)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "integral-costs",
   "metadata": {},
   "source": [
    "##### Read test data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 175,
   "id": "acute-wallet",
   "metadata": {},
   "outputs": [],
   "source": [
    "filename_testlabels = \"nwcsaf_msevi-nawdex-20160920.nc\"\n",
    "filename_testdata = \"msevi-nawdex-20160920.nc\"\n",
    "hour = 0\n",
    "\n",
    "raw_test_data = xr.open_dataset(data_directory+filename_testdata)\n",
    "raw_test_label = xr.open_dataset(data_directory+filename_testlabels)\n",
    "\n",
    "\n",
    "### read test data, apply region-mapping, convert into form usable by classifier\n",
    "test_data = []\n",
    "for variable in raw_test_data.variables:\n",
    "     if \"bt\" in variable:\n",
    "        masked_channel = raw_test_data[variable][hour].where(mask_ds[\"mediterranean_mask\"])\n",
    "        test_data.append(np.array(masked_channel).flatten())\n",
    "test_data = np.array(test_data)\n",
    "sp = test_data.shape\n",
    "test_data = test_data.flatten().reshape(sp[1],sp[0], order='F')\n",
    "\n",
    "test_label = raw_test_label[\"CT\"][hour].where(mask_ds[\"mediterranean_mask\"])\n",
    "test_label = np.array(test_label).flatten()\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 189,
   "id": "ongoing-awareness",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(2787104, 8)"
      ]
     },
     "execution_count": 189,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "nan_label = np.isnan(test_label)\n",
    "nan_data = []np.any()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 155,
   "id": "external-clause",
   "metadata": {},
   "outputs": [
    {
     "ename": "ValueError",
     "evalue": "Input contains NaN, infinity or a value too large for dtype('float32').",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-155-af896e8ef74a>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mcl\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpredict\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtest_data\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;32m~/.local/lib/python3.8/site-packages/sklearn/tree/_classes.py\u001b[0m in \u001b[0;36mpredict\u001b[0;34m(self, X, check_input)\u001b[0m\n\u001b[1;32m    435\u001b[0m         \"\"\"\n\u001b[1;32m    436\u001b[0m         \u001b[0mcheck_is_fitted\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 437\u001b[0;31m         \u001b[0mX\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_validate_X_predict\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mX\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcheck_input\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    438\u001b[0m         \u001b[0mproba\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtree_\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpredict\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mX\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    439\u001b[0m         \u001b[0mn_samples\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mX\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mshape\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/.local/lib/python3.8/site-packages/sklearn/tree/_classes.py\u001b[0m in \u001b[0;36m_validate_X_predict\u001b[0;34m(self, X, check_input)\u001b[0m\n\u001b[1;32m    400\u001b[0m         \u001b[0;34m\"\"\"Validate the training data on predict (probabilities).\"\"\"\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    401\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mcheck_input\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 402\u001b[0;31m             X = self._validate_data(X, dtype=DTYPE, accept_sparse=\"csr\",\n\u001b[0m\u001b[1;32m    403\u001b[0m                                     reset=False)\n\u001b[1;32m    404\u001b[0m             if issparse(X) and (X.indices.dtype != np.intc or\n",
      "\u001b[0;32m~/.local/lib/python3.8/site-packages/sklearn/base.py\u001b[0m in \u001b[0;36m_validate_data\u001b[0;34m(self, X, y, reset, validate_separately, **check_params)\u001b[0m\n\u001b[1;32m    419\u001b[0m             \u001b[0mout\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mX\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    420\u001b[0m         \u001b[0;32melif\u001b[0m \u001b[0misinstance\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0my\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mstr\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mand\u001b[0m \u001b[0my\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0;34m'no_validation'\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 421\u001b[0;31m             \u001b[0mX\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mcheck_array\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mX\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mcheck_params\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    422\u001b[0m             \u001b[0mout\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mX\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    423\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/.local/lib/python3.8/site-packages/sklearn/utils/validation.py\u001b[0m in \u001b[0;36minner_f\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m     61\u001b[0m             \u001b[0mextra_args\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m-\u001b[0m \u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mall_args\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     62\u001b[0m             \u001b[0;32mif\u001b[0m \u001b[0mextra_args\u001b[0m \u001b[0;34m<=\u001b[0m \u001b[0;36m0\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 63\u001b[0;31m                 \u001b[0;32mreturn\u001b[0m \u001b[0mf\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     64\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     65\u001b[0m             \u001b[0;31m# extra_args > 0\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/.local/lib/python3.8/site-packages/sklearn/utils/validation.py\u001b[0m in \u001b[0;36mcheck_array\u001b[0;34m(array, accept_sparse, accept_large_sparse, dtype, order, copy, force_all_finite, ensure_2d, allow_nd, ensure_min_samples, ensure_min_features, estimator)\u001b[0m\n\u001b[1;32m    661\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    662\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mforce_all_finite\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 663\u001b[0;31m             _assert_all_finite(array,\n\u001b[0m\u001b[1;32m    664\u001b[0m                                allow_nan=force_all_finite == 'allow-nan')\n\u001b[1;32m    665\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/.local/lib/python3.8/site-packages/sklearn/utils/validation.py\u001b[0m in \u001b[0;36m_assert_all_finite\u001b[0;34m(X, allow_nan, msg_dtype)\u001b[0m\n\u001b[1;32m    101\u001b[0m                 not allow_nan and not np.isfinite(X).all()):\n\u001b[1;32m    102\u001b[0m             \u001b[0mtype_err\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m'infinity'\u001b[0m \u001b[0;32mif\u001b[0m \u001b[0mallow_nan\u001b[0m \u001b[0;32melse\u001b[0m \u001b[0;34m'NaN, infinity'\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 103\u001b[0;31m             raise ValueError(\n\u001b[0m\u001b[1;32m    104\u001b[0m                     \u001b[0mmsg_err\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mformat\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    105\u001b[0m                     (type_err,\n",
      "\u001b[0;31mValueError\u001b[0m: Input contains NaN, infinity or a value too large for dtype('float32')."
     ]
    }
   ],
   "source": [
    "cl.predict(test_data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fresh-province",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "peaceful-wrist",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "median-broadcast",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "generic-routine",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "latter-valentine",
   "metadata": {},
   "source": [
    "### test stuff and such"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 99,
   "id": "brief-absence",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(8, 2400)"
      ]
     },
     "execution_count": 99,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "training_data.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 102,
   "id": "limiting-custody",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([ 2.,  2., 16., ..., 12.,  2.,  8.], dtype=float32)"
      ]
     },
     "execution_count": 102,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "labels"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "advance-filter",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 123,
   "id": "positive-southwest",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[ 1,  9, 11],\n",
       "       [ 2,  8, 11],\n",
       "       [ 3,  9, 11],\n",
       "       [ 4,  7, 11],\n",
       "       [ 5,  9, 11]])"
      ]
     },
     "execution_count": 123,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "a = np.array([[1,2,3,4,5],[9,8,9,7,9], [11,11,11,11,11]])\n",
    "a.flatten().reshape((5,3), order='F')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "black-grenada",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "informal-austin",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "opponent-furniture",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
